{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e809cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\USER\\Documents\\Heart_Disease Kaggle\\Data\\heart.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PHASE 4: DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# STEP 1: Handle missing values (zeros)\n",
    "print(\"\\n1. Handling missing values...\")\n",
    "for disease_status in [0, 1]:\n",
    "    median_bp = df[df['HeartDisease'] == disease_status]['RestingBP'].median()\n",
    "    median_chol = df[df['HeartDisease'] == disease_status]['Cholesterol'].median()\n",
    "    \n",
    "    df.loc[(df['RestingBP'] == 0) & (df['HeartDisease'] == disease_status), 'RestingBP'] = median_bp\n",
    "    df.loc[(df['Cholesterol'] == 0) & (df['HeartDisease'] == disease_status), 'Cholesterol'] = median_chol\n",
    "\n",
    "print(f\"   RestingBP zeros: {(df['RestingBP'] == 0).sum()}\")\n",
    "print(f\"   Cholesterol zeros: {(df['Cholesterol'] == 0).sum()}\")\n",
    "\n",
    "# STEP 2: Encode categorical variables\n",
    "print(\"\\n2. Encoding categorical variables...\")\n",
    "categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ST_Slope', 'ExerciseAngina']\n",
    "encoders = {}\n",
    "\n",
    "# Label encode binary\n",
    "for col in ['Sex', 'ExerciseAngina']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "    print(f\"   {col}: Encoded\")\n",
    "\n",
    "# One-hot encode nominal\n",
    "for col in ['ChestPainType', 'RestingECG', 'ST_Slope']:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print(f\"   Dataset shape after encoding: {df.shape}\")\n",
    "\n",
    "# STEP 3: Feature engineering\n",
    "print(\"\\n3. Creating new features...\")\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 30, 40, 50, 60, 100], labels=[0, 1, 2, 3, 4])\n",
    "df['HR_Age_Ratio'] = df['MaxHR'] / (df['Age'] + 1)\n",
    "df['Cholesterol_High'] = (df['Cholesterol'] > 200).astype(int)\n",
    "print(f\"   3 new features created\")\n",
    "\n",
    "# STEP 4: Split train-test (80-20 stratified)\n",
    "print(\"\\n4. Splitting train-test sets...\")\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"   Train set: {X_train.shape}\")\n",
    "print(f\"   Test set: {X_test.shape}\")\n",
    "\n",
    "# STEP 5: Scale numerical features\n",
    "print(\"\\n5. Scaling numerical features...\")\n",
    "numerical_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak', 'HR_Age_Ratio']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(f\"   Features scaled successfully\")\n",
    "\n",
    "# STEP 6: Save artifacts\n",
    "print(\"\\n6. Saving preprocessed data and artifacts...\")\n",
    "# Ensure target directories exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "# Ensure scaled outputs are DataFrames before saving\n",
    "if isinstance(X_train_scaled, np.ndarray):\n",
    "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "else:\n",
    "    X_train_df = X_train_scaled\n",
    "if isinstance(X_test_scaled, np.ndarray):\n",
    "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "else:\n",
    "    X_test_df = X_test_scaled\n",
    "X_train_df.to_csv('data/X_train_scaled.csv', index=False)\n",
    "X_test_df.to_csv('data/X_test_scaled.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)\n",
    "\n",
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('models/encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "\n",
    "print(f\"   All files saved successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ PHASE 4 COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal features: {df.shape}\")\n",
    "print(f\"Final features: {X_train_scaled.shape}\")\n",
    "print(f\"\\nReady for Phase 5: Model Building\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease_status in [0, 1]:\n",
    "    median_bp = df[df['HeartDisease']==disease_status]['RestingBP'].median()\n",
    "    df.loc[(df['RestingBP']==0)&(df['HeartDisease']==disease_status), 'RestingBP'] = median_bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef481cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode binary (only if needed)\n",
    "if 'Sex' in df.columns and df['Sex'].dtype == object:\n",
    "    le = LabelEncoder()\n",
    "    df['Sex'] = le.fit_transform(df['Sex'])\n",
    "    print(\"  Sex: encoded\")\n",
    "else:\n",
    "    print(\"  Sex already encoded or not present; skipping\")\n",
    "\n",
    "# One-hot encode nominal (only if column exists)\n",
    "if 'ChestPainType' in df.columns:\n",
    "    dummies = pd.get_dummies(df['ChestPainType'], prefix='CPT', drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop('ChestPainType', axis=1, inplace=True)\n",
    "    print(\"  ChestPainType: one-hot encoded\")\n",
    "else:\n",
    "    print(\"  ChestPainType not found; skipping one-hot encoding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0,30,40,50,60,100], labels=[0,1,2,3,4])\n",
    "df['HR_Age_Ratio'] = df['MaxHR'] / (df['Age'] + 1)\n",
    "df['Cholesterol_High'] = (df['Cholesterol'] > 200).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c540b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(data):\n",
    "    Q1, Q3 = data.quantile(0.25), data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return (data < Q1-1.5*IQR) | (data > Q3+1.5*IQR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1462e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce113bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Determine numeric columns to scale (safe fallback)\n",
    "numerical_cols = [c for c in X_train.columns if X_train[c].dtype.kind in 'bifc']\n",
    "# Create DataFrame copies and scale numeric columns only\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv('data/X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv('data/X_test_scaled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa084503",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test shape: {X_test_scaled.shape}\")\n",
    "print(f\"Missing values: {X_train_scaled.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53410d5",
   "metadata": {},
   "source": [
    "## Phase 4 — Data Preprocessing & Feature Engineering\n",
    "\n",
    "This document summarizes the preprocessing and feature engineering performed in `Notebooks/Phase4.ipynb`, lists the artifacts produced, and provides quick run and troubleshooting instructions.\n",
    "\n",
    "- **Purpose:** Prepare the cleaned, encoded, and scaled datasets for modeling (Phase 5). Create reproducible preprocessing artifacts such as scaled CSVs and serialized transformers/encoders.\n",
    "- **Notebook:** `Notebooks/Phase4.ipynb`\n",
    "\n",
    "**Produced Artifacts**\n",
    "- `data/X_train_scaled.csv`: Scaled training features (DataFrame CSV).\n",
    "- `data/X_test_scaled.csv`: Scaled test features (DataFrame CSV).\n",
    "- `data/y_train.csv`, `data/y_test.csv`: Target splits as CSVs.\n",
    "- `models/scaler.pkl`: Pickled `StandardScaler` fitted on training data.\n",
    "- `models/encoders.pkl`: Pickled dictionary of encoders (e.g., `LabelEncoder` instances).\n",
    "\n",
    "**Main Steps (high level)**\n",
    "- Handle missing / sentinel values: median-impute zeros in `RestingBP` and `Cholesterol` grouped by `HeartDisease` status.\n",
    "- Encode categorical variables:\n",
    "  - Label-encode binary columns (e.g., `Sex`, `ExerciseAngina`).\n",
    "  - One-hot encode nominal columns (e.g., `ChestPainType`, `RestingECG`, `ST_Slope`) when present.\n",
    "- Create features such as `Age_Group`, `HR_Age_Ratio`, and `Cholesterol_High`.\n",
    "- Split the dataset via `train_test_split(..., stratify=y, test_size=0.2)`.\n",
    "- Scale numeric columns with `StandardScaler` fit on the training set only.\n",
    "- Persist CSVs and pickled artifacts to the `data/` and `models/` directories.\n",
    "\n",
    "**How to run (PowerShell)**\n",
    "1. From the project root, execute the notebook headless (example):\n",
    "\n",
    "```powershell\n",
    "python -m nbconvert --to notebook --execute \"Notebooks\\Phase4.ipynb\" --output \"Notebooks\\Phase4_executed.ipynb\"\n",
    "```\n",
    "\n",
    "2. Or run interactively in VS Code / Jupyter and execute cells in order.\n",
    "\n",
    "**Notes & Troubleshooting**\n",
    "- Missing output directories: The notebook creates `data/` and `models/` using `os.makedirs(..., exist_ok=True)` before saving. If you still see a `FileNotFoundError`, confirm file system permissions and that the notebook is run from the project root.\n",
    "- `AttributeError: 'numpy.ndarray' object has no attribute 'to_csv'`: Fixed — numeric scaling is applied to numeric columns of DataFrame copies so `X_train_scaled` / `X_test_scaled` remain DataFrames. If you encounter this, ensure the scaling cell produces DataFrames (not raw numpy arrays) before calling `to_csv`.\n",
    "- Missing categorical columns (e.g., `ChestPainType`): The notebook checks for column existence before one-hot encoding and skips the step if the column is absent.\n",
    "- Encoder serialization: `models/encoders.pkl` contains a dictionary of fitted encoders; ensure you load these when transforming new data for inference.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
