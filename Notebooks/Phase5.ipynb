{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "X_train = pd.read_csv('data/X_train_scaled.csv')\n",
    "X_test = pd.read_csv('data/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('data/y_test.csv').values.ravel()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PHASE 5: MODEL BUILDING & TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "}\n",
    "\n",
    "print(f\"\\n1. Training {len(models)} models...\")\n",
    "\n",
    "# Train all models\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f\"   ✓ {name}\")\n",
    "\n",
    "print(f\"\\n2. Evaluating on test set...\")\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Compare\n",
    "comparison_df = pd.DataFrame(results).T.sort_values('F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "print(comparison_df)\n",
    "\n",
    "# Extract best model name (first row after sort)\n",
    "best_model_name = comparison_df.index[0]\n",
    "best_f1_score = comparison_df.loc[best_model_name, 'F1']\n",
    "\n",
    "print(f\"\\n✓ BEST MODEL: {best_model_name}\")\n",
    "print(f\"  F1-Score: {best_f1_score:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ PHASE 5 COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65948bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbfb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(results).T.sort_values('F1', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = trained_models['Random Forest']\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9590e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensure models directory exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Get best model from trained_models\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "with open('models/best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"Best model ({best_model_name}) saved to models/best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5980c",
   "metadata": {},
   "source": [
    "## Phase 5 — Model Building & Training\n",
    "\n",
    "This document summarizes the model training and evaluation performed in `Notebooks/Phase5.ipynb`, lists the artifacts produced, and provides quick run and troubleshooting instructions.\n",
    "\n",
    "- **Purpose:** Build, train, and evaluate multiple machine learning models on preprocessed data. Compare performance metrics and identify the best model for deployment.\n",
    "- **Notebook:** `Notebooks/Phase5.ipynb`\n",
    "\n",
    "**Produced Artifacts**\n",
    "- `models/best_model.pkl`: Pickled best-performing model (selected by F1-score).\n",
    "- Console output: Model comparison table with accuracy, precision, recall, F1, and ROC-AUC scores.\n",
    "\n",
    "**Main Steps (high level)**\n",
    "- Load preprocessed training and test data from `data/` directory (CSVs created in Phase 4).\n",
    "- Initialize 5 classification models:\n",
    "  - Logistic Regression (max_iter=1000)\n",
    "  - Random Forest (n_estimators=100)\n",
    "  - Gradient Boosting\n",
    "  - SVM (with probability=True for ROC-AUC)\n",
    "  - K-Nearest Neighbors (n_neighbors=5)\n",
    "- Train all models on the training set.\n",
    "- Evaluate each model on the test set, computing:\n",
    "  - Accuracy, Precision, Recall, F1-score, ROC-AUC\n",
    "- Rank models by F1-score and identify the best performer.\n",
    "- Serialize the best model to `models/best_model.pkl` for future inference.\n",
    "\n",
    "**How to run (PowerShell)**\n",
    "1. From the project root, execute the notebook headless (example):\n",
    "\n",
    "```powershell\n",
    "python -m nbconvert --to notebook --execute \"Notebooks\\Phase5.ipynb\" --output \"Notebooks\\Phase5_executed.ipynb\"\n",
    "```\n",
    "\n",
    "2. Or run interactively in VS Code / Jupyter and execute cells in order.\n",
    "\n",
    "**Notes & Troubleshooting**\n",
    "- Missing `data/` files: Phase 5 loads preprocessed CSVs created by Phase 4. Ensure Phase 4 has been executed and `data/X_train_scaled.csv`, `data/X_test_scaled.csv`, `data/y_train.csv`, and `data/y_test.csv` exist.\n",
    "- `NameError: name 'best_model' is not defined`: This occurred if the model-saving cell was run before cell 1 (which defines `best_model_name` and trains models). Run cells in order.\n",
    "- `FileNotFoundError` when saving to `models/`: The notebook creates the `models/` directory automatically via `os.makedirs('models', exist_ok=True)` before saving. If this fails, check file system permissions.\n",
    "- Model evaluation slow: Training 5 models (especially Random Forest and Gradient Boosting) may take time on larger datasets. Reduce `n_estimators` or simplify model parameters if needed.\n",
    "\n",
    "**Model Comparison Output**\n",
    "The notebook prints a comparison table showing metrics for all models. Example:\n",
    "\n",
    "```\n",
    "--------------------------------------------\n",
    "MODEL COMPARISON\n",
    "--------------------------------------------\n",
    "                      Accuracy  Precision  Recall    F1  ROC-AUC\n",
    "Model Name               ...      ...      ...    ...     ...\n",
    "```\n",
    "\n",
    "The model with the highest F1-score is selected as the best model and saved.\n",
    "\n",
    "**Next steps**\n",
    "- Verify that `models/best_model.pkl` was created after running Phase 5.\n",
    "- Load and use the best model for inference on new data (e.g., in a production pipeline).\n",
    "- Optionally, perform hyperparameter tuning on the best model to improve performance.\n",
    "- Use the feature importances (from Random Forest) to understand which features drive predictions.\n",
    "\n",
    "**Quick validation**\n",
    "After running, confirm these files exist:\n",
    "- `models/best_model.pkl` ✓\n",
    "- Console output shows F1-scores for all 5 models ✓\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
