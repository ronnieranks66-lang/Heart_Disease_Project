{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\USER\\Documents\\Heart_Disease Kaggle\\Data\\heart.csv\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PHASE 2: DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df['HeartDisease'].value_counts())\n",
    "print(f\"\\n✓ Phase 2 started successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24469662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHASE 2: DATA COLLECTION & EXPLORATION\n",
    "# Heart Disease Prediction Project\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Project info\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: DATA COLLECTION & EXPLORATION\")\n",
    "print(\"Heart Disease Prediction Project\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDate: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Status: Starting data exploration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: LOAD THE DATASET\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: LOADING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\USER\\Documents\\Heart_Disease Kaggle\\Data\\heart.csv\")\n",
    "\n",
    "print(f\"\\n✓ Dataset loaded successfully!\")\n",
    "print(f\"  File: heart.csv\")\n",
    "print(f\"  Location: Current directory\")\n",
    "print(f\"  Size: {df.shape} rows × {df.shape} columns\")\n",
    "\n",
    "# Save info for later\n",
    "dataset_shape = df.shape\n",
    "print(f\"\\n  Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aed1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2: INITIAL DATASET INSPECTION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nLast 5 rows of the dataset:\")\n",
    "print(df.tail())\n",
    "\n",
    "# Column names and types\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"-\"*80)\n",
    "print(f\"\\nColumn Names ({len(df.columns)} total):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"-\"*80)\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15330b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3: DATA QUALITY CHECK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: DATA QUALITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percent': missing_percent.values\n",
    "})\n",
    "\n",
    "# Filter to show only columns with missing values\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(missing_summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found in the dataset!\")\n",
    "\n",
    "# Duplicates\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DUPLICATE ROWS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nTotal duplicate rows: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"! Found {duplicate_count} duplicate rows\")\n",
    "    print(\"\\nFirst few duplicates:\")\n",
    "    print(df[df.duplicated(keep=False)].head())\n",
    "else:\n",
    "    print(\"✓ No duplicate rows found!\")\n",
    "\n",
    "# Data shape confirmation\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DATASET DIMENSIONS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"\\nTotal rows: {df.shape[0]}\")\n",
    "print(f\"Total columns: {df.shape[1]}\")\n",
    "print(f\"Total cells: {df.shape[0] * df.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e443c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 4: DESCRIPTIVE STATISTICS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"NUMERICAL FEATURES SUMMARY\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# More detailed statistics\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DETAILED STATISTICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Count:     {df[col].count()}\")\n",
    "    print(f\"  Mean:      {df[col].mean():.4f}\")\n",
    "    print(f\"  Median:    {df[col].median():.4f}\")\n",
    "    print(f\"  Std Dev:   {df[col].std():.4f}\")\n",
    "    print(f\"  Min:       {df[col].min():.4f}\")\n",
    "    print(f\"  Max:       {df[col].max():.4f}\")\n",
    "    print(f\"  Q1 (25%):  {df[col].quantile(0.25):.4f}\")\n",
    "    print(f\"  Q3 (75%):  {df[col].quantile(0.75):.4f}\")\n",
    "    print(f\"  IQR:       {df[col].quantile(0.75) - df[col].quantile(0.25):.4f}\")\n",
    "    print(f\"  Skewness:  {df[col].skew():.4f}\")\n",
    "    print(f\"  Kurtosis:  {df[col].kurtosis():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: CATEGORICAL FEATURES ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Values: {df[col].unique().tolist()}\")\n",
    "    print(f\"  Value counts:\")\n",
    "    print(df[col].value_counts())\n",
    "    print(f\"  Distribution (%):\")\n",
    "    print(df[col].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4965b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 6: TARGET VARIABLE ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: TARGET VARIABLE ANALYSIS (HeartDisease)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target = 'HeartDisease'\n",
    "\n",
    "print(f\"\\n{target} Distribution:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Value counts\n",
    "print(\"\\nAbsolute counts:\")\n",
    "print(df[target].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nPercentage distribution:\")\n",
    "target_dist = df[target].value_counts(normalize=True) * 100\n",
    "print(target_dist.sort_index())\n",
    "\n",
    "# Analysis\n",
    "value_counts = df[target].value_counts().sort_index()\n",
    "no_disease_count = value_counts.get(0, 0)\n",
    "disease_count = value_counts.get(1, 0)\n",
    "total = len(df)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TARGET VARIABLE BREAKDOWN\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nNo Heart Disease (0): {no_disease_count} ({no_disease_count/total*100:.2f}%)\")\n",
    "print(f\"Heart Disease (1):    {disease_count} ({disease_count/total*100:.2f}%)\")\n",
    "print(f\"Total:                {total}\")\n",
    "\n",
    "# Class balance assessment\n",
    "if no_disease_count > 0 and disease_count > 0:\n",
    "    ratio = max(no_disease_count, disease_count) / min(no_disease_count, disease_count)\n",
    "    print(f\"\\nClass imbalance ratio: {ratio:.2f}:1\")\n",
    "\n",
    "    if ratio < 1.1:\n",
    "        print(\"✓ Classes are well-balanced (excellent for modeling)\")\n",
    "    elif ratio < 1.5:\n",
    "        print(\"✓ Classes are reasonably balanced\")\n",
    "    elif ratio < 2.0:\n",
    "        print(\"! Classes have slight imbalance (manageable)\")\n",
    "    else:\n",
    "        print(\"! Classes have significant imbalance (requires attention)\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\nTarget distribution plot saved below...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 7: CHECK FOR PROBLEMATIC VALUES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: CHECKING FOR PROBLEMATIC VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for zeros in medical features where zeros might be invalid\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"\\nZero value counts in numerical features:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    zero_percent = (zero_count / len(df)) * 100\n",
    "    \n",
    "    if zero_count > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Zero values: {zero_count} ({zero_percent:.2f}%)\")\n",
    "        \n",
    "        # Flag problematic columns\n",
    "        if col in ['RestingBP', 'Cholesterol']:\n",
    "            print(f\"  ⚠️  WARNING: {col} has {zero_count} zeros - likely missing values!\")\n",
    "        else:\n",
    "            print(f\"  Note: {zero_count} zeros in {col}\")\n",
    "\n",
    "# Check for negative values\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"NEGATIVE VALUES CHECK\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "negative_found = False\n",
    "for col in numeric_cols:\n",
    "    neg_count = (df[col] < 0).sum()\n",
    "    if neg_count > 0:\n",
    "        print(f\"\\n{col}: {neg_count} negative values\")\n",
    "        print(f\"  Range: {df[col].min()} to {df[col].max()}\")\n",
    "        negative_found = True\n",
    "\n",
    "if not negative_found:\n",
    "    print(\"\\n✓ No negative values found (expected)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 8: FEATURE DICTIONARY & SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: COMPLETE FEATURE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_summary = {\n",
    "    'Age': {\n",
    "        'Type': 'Numerical',\n",
    "        'Description': 'Patient age in years',\n",
    "        'Min': df['Age'].min(),\n",
    "        'Max': df['Age'].max(),\n",
    "        'Mean': df['Age'].mean(),\n",
    "        'Zeros': (df['Age'] == 0).sum()\n",
    "    },\n",
    "    'Sex': {\n",
    "        'Type': 'Categorical',\n",
    "        'Description': 'Gender (M/F)',\n",
    "        'Unique_Values': df['Sex'].nunique(),\n",
    "        'Values': df['Sex'].unique().tolist(),\n",
    "        'Mode': df['Sex'].mode()\n",
    "    },\n",
    "    'ChestPainType': {\n",
    "        'Type': 'Categorical',\n",
    "        'Description': 'Type of chest pain',\n",
    "        'Unique_Values': df['ChestPainType'].nunique(),\n",
    "        'Values': sorted(df['ChestPainType'].unique().tolist()),\n",
    "        'Mode': df['ChestPainType'].mode()\n",
    "    },\n",
    "    'RestingBP': {\n",
    "        'Type': 'Numerical',\n",
    "        'Description': 'Resting blood pressure (mm Hg)',\n",
    "        'Min': df['RestingBP'].min(),\n",
    "        'Max': df['RestingBP'].max(),\n",
    "        'Mean': df['RestingBP'].mean(),\n",
    "        'Zeros': (df['RestingBP'] == 0).sum(),\n",
    "        'Status': '⚠️ Has zeros' if (df['RestingBP'] == 0).sum() > 0 else '✓'\n",
    "    },\n",
    "    'Cholesterol': {\n",
    "        'Type': 'Numerical',\n",
    "        'Description': 'Serum cholesterol (mg/dl)',\n",
    "        'Min': df['Cholesterol'].min(),\n",
    "        'Max': df['Cholesterol'].max(),\n",
    "        'Mean': df['Cholesterol'].mean(),\n",
    "        'Zeros': (df['Cholesterol'] == 0).sum(),\n",
    "        'Status': '⚠️ Has zeros' if (df['Cholesterol'] == 0).sum() > 0 else '✓'\n",
    "    },\n",
    "    'FastingBS': {\n",
    "        'Type': 'Binary',\n",
    "        'Description': 'Fasting blood sugar > 120 mg/dl',\n",
    "        'Unique_Values': df['FastingBS'].nunique(),\n",
    "        'Values': sorted(df['FastingBS'].unique().tolist()),\n",
    "        'Distribution': df['FastingBS'].value_counts().to_dict()\n",
    "    },\n",
    "    'RestingECG': {\n",
    "        'Type': 'Categorical',\n",
    "        'Description': 'Resting ECG results',\n",
    "        'Unique_Values': df['RestingECG'].nunique(),\n",
    "        'Values': sorted(df['RestingECG'].unique().tolist()),\n",
    "        'Mode': df['RestingECG'].mode()\n",
    "    },\n",
    "    'MaxHR': {\n",
    "        'Type': 'Numerical',\n",
    "        'Description': 'Maximum heart rate achieved (bpm)',\n",
    "        'Min': df['MaxHR'].min(),\n",
    "        'Max': df['MaxHR'].max(),\n",
    "        'Mean': df['MaxHR'].mean(),\n",
    "        'Zeros': (df['MaxHR'] == 0).sum()\n",
    "    },\n",
    "    'ExerciseAngina': {\n",
    "        'Type': 'Binary',\n",
    "        'Description': 'Exercise-induced angina',\n",
    "        'Unique_Values': df['ExerciseAngina'].nunique(),\n",
    "        'Values': df['ExerciseAngina'].unique().tolist(),\n",
    "        'Distribution': df['ExerciseAngina'].value_counts().to_dict()\n",
    "    },\n",
    "    'Oldpeak': {\n",
    "        'Type': 'Numerical',\n",
    "        'Description': 'ST depression from baseline (mm)',\n",
    "        'Min': df['Oldpeak'].min(),\n",
    "        'Max': df['Oldpeak'].max(),\n",
    "        'Mean': df['Oldpeak'].mean(),\n",
    "        'Zeros': (df['Oldpeak'] == 0).sum()\n",
    "    },\n",
    "    'ST_Slope': {\n",
    "        'Type': 'Categorical',\n",
    "        'Description': 'Slope of ST segment',\n",
    "        'Unique_Values': df['ST_Slope'].nunique(),\n",
    "        'Values': sorted(df['ST_Slope'].unique().tolist()),\n",
    "        'Mode': df['ST_Slope'].mode()\n",
    "    },\n",
    "    'HeartDisease': {\n",
    "        'Type': 'Binary (TARGET)',\n",
    "        'Description': 'Presence of heart disease',\n",
    "        'Unique_Values': df['HeartDisease'].nunique(),\n",
    "        'Values': sorted(df['HeartDisease'].unique().tolist()),\n",
    "        'Distribution': df['HeartDisease'].value_counts().to_dict(),\n",
    "        'Class_Balance': f\"{df['HeartDisease'].value_counts()} vs {df['HeartDisease'].value_counts()}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "for feature, info in feature_summary.items():\n",
    "    print(f\"\\n{feature}:\")\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57be99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 9: EXPLORATORY VISUALIZATIONS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Target Variable Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "df['HeartDisease'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Heart Disease Distribution (Count)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Heart Disease (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['No Disease', 'Disease'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "df['HeartDisease'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',\n",
    "                                       colors=['#2ecc71', '#e74c3c'], labels=['No Disease', 'Disease'])\n",
    "axes[1].set_title('Heart Disease Distribution (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Target distribution plot saved: 01_target_distribution.png\")\n",
    "\n",
    "# 2. Numerical Features Distribution (exclude target variable)\n",
    "numerical_features = [col for col in df.select_dtypes(include=[np.number]).columns if col != 'HeartDisease']\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].hist(df[col], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(len(numerical_features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('02_numerical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Numerical distributions plot saved: 02_numerical_distributions.png\")\n",
    "\n",
    "# 3. Categorical Features Distribution\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    df[col].value_counts().plot(kind='bar', ax=axes[idx], color='steelblue')\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Categorical distributions plot saved: 03_categorical_distributions.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 10: GENERATE DATA QUALITY REPORT\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: DATA QUALITY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "report = f\"\"\"\n",
    "PHASE 2: DATA EXPLORATION REPORT\n",
    "Heart Disease Prediction Project\n",
    "\n",
    "DATASET SUMMARY\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Total Records:              {df.shape[0]:,}\n",
    "Total Features:             {df.shape[1]}\n",
    "Total Cells:                {df.shape[0] * df.shape[1]:,}\n",
    "Dataset Size:               {df.memory_usage(deep=True).sum() / 1024:.2f} KB\n",
    "\n",
    "FEATURE BREAKDOWN\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Numerical Features:         {len(df.select_dtypes(include=[np.number]).columns)} columns\n",
    "Categorical Features:       {len(df.select_dtypes(include=['object']).columns)} columns\n",
    "Binary Features:            2 (FastingBS, ExerciseAngina)\n",
    "Target Variable:            1 (HeartDisease)\n",
    "\n",
    "DATA QUALITY\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Missing Values:             {df.isnull().sum().sum()} (0%)\n",
    "Duplicate Rows:             {df.duplicated().sum()}\n",
    "Data Type Issues:           None detected [OK]\n",
    "\n",
    "PROBLEMATIC VALUES DETECTED\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "RestingBP with zeros:       {(df['RestingBP'] == 0).sum()} records [WARNING]\n",
    "Cholesterol with zeros:     {(df['Cholesterol'] == 0).sum()} records [WARNING]\n",
    "Action Required:            Handle zeros in preprocessing phase\n",
    "\n",
    "TARGET VARIABLE ANALYSIS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\"\"\"\n",
    "\n",
    "# Get target counts\n",
    "target_counts = df['HeartDisease'].value_counts().sort_index()\n",
    "no_disease = target_counts.get(0, 0)\n",
    "disease = target_counts.get(1, 0)\n",
    "total = len(df)\n",
    "\n",
    "report += f\"\"\"No Heart Disease (0):       {no_disease} ({no_disease/total*100:.2f}%)\n",
    "Heart Disease (1):          {disease} ({disease/total*100:.2f}%)\n",
    "Class Balance Status:        [EXCELLENT] Nearly 50-50 split\n",
    "\n",
    "NUMERICAL FEATURES SUMMARY\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\"\"\"\n",
    "\n",
    "# Add numerical stats\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    report += f\"\\n{col:20} Mean: {df[col].mean():8.2f}  Std: {df[col].std():8.2f}  Range: [{df[col].min():8.2f}, {df[col].max():8.2f}]\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "CATEGORICAL FEATURES SUMMARY\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\"\"\"\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    mode_val = df[col].mode()[0] if len(df[col].mode()) > 0 else \"N/A\"\n",
    "    report += f\"\\n{col:20} Unique: {df[col].nunique():3}  Mode: {mode_val}\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "KEY FINDINGS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "1. [OK] Dataset is clean with no missing values\n",
    "2. [OK] No duplicate records found\n",
    "3. [OK] Target variable is well-balanced (nearly 50-50 split)\n",
    "4. [WARNING] RestingBP and Cholesterol contain zeros (likely missing values)\n",
    "5. [OK] All feature types are correctly identified\n",
    "6. [OK] Ready for preprocessing phase\n",
    "\n",
    "RECOMMENDATIONS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Phase 3 Actions:\n",
    "  1. Create comprehensive EDA with visualizations\n",
    "  2. Analyze feature correlations\n",
    "  3. Identify outliers and distributions\n",
    "  4. Plan feature engineering\n",
    "  \n",
    "Phase 4 Actions:\n",
    "  1. Handle zeros in RestingBP and Cholesterol\n",
    "  2. Encode categorical variables\n",
    "  3. Scale numerical features\n",
    "  4. Split train-test data\n",
    "\n",
    "PHASE 2 STATUS: COMPLETE\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Ready for Phase 3: Exploratory Data Analysis (EDA)\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "import os\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "with open('reports/phase2_data_exploration_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n✓ Report saved: reports/phase2_data_exploration_report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 11: SAVE YOUR WORK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 11: SAVING PHASE 2 OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save raw data to data folder (if not already there)\n",
    "# df.to_csv('data/heart_raw.csv', index=False)\n",
    "# print(\"✓ Raw data saved: data/heart_raw.csv\")\n",
    "\n",
    "# Create a session summary\n",
    "session_summary = f\"\"\"\n",
    "PHASE 2 SESSION SUMMARY\n",
    "================================================================================\n",
    "Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Status: Phase 2 Complete [OK]\n",
    "\n",
    "DATASET LOADED\n",
    "  File: heart.csv\n",
    "  Rows: {df.shape[0]}\n",
    "  Columns: {df.shape[1]}\n",
    "\n",
    "DATA QUALITY CHECKS\n",
    "  Missing Values: [OK] PASS (None)\n",
    "  Duplicates: [OK] PASS (None)\n",
    "  Data Types: [OK] PASS (Correct)\n",
    "\n",
    "TARGET VARIABLE\n",
    "  HeartDisease Distribution: Well-balanced\n",
    "  Class Balance: [EXCELLENT]\n",
    "\n",
    "VISUALIZATIONS CREATED\n",
    "  01_target_distribution.png\n",
    "  02_numerical_distributions.png\n",
    "  03_categorical_distributions.png\n",
    "\n",
    "FILES GENERATED\n",
    "  reports/phase2_data_exploration_report.txt\n",
    "\n",
    "READY FOR\n",
    "  Phase 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "NEXT STEPS\n",
    "  1. Review visualizations created in this phase\n",
    "  2. Create phase3_eda_analysis.ipynb\n",
    "  3. Perform detailed feature analysis\n",
    "  4. Identify patterns and relationships\n",
    "  5. Document insights for modeling\n",
    "\"\"\"\n",
    "\n",
    "with open('reports/phase2_session_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(session_summary)\n",
    "\n",
    "print(\"✓ Session summary saved: reports/phase2_session_summary.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2 COMPLETE! [OK]\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  • 01_target_distribution.png\")\n",
    "print(\"  • 02_numerical_distributions.png\")\n",
    "print(\"  • 03_categorical_distributions.png\")\n",
    "print(\"  • reports/phase2_data_exploration_report.txt\")\n",
    "print(\"  • reports/phase2_session_summary.txt\")\n",
    "print(\"\\nReady to proceed to Phase 3: Exploratory Data Analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d317a",
   "metadata": {},
   "source": [
    "# Phase 2 — Data Collection & Exploration — README\n",
    "\n",
    "Summary\n",
    "-------\n",
    "This document describes Phase 2 of the Heart Disease prediction project: Data Collection & Exploration. The primary notebook is `Notebooks/Phase2.ipynb`. Use this README to reproduce the Phase 2 outputs, find generated artifacts, and follow recommended next steps.\n",
    "\n",
    "Quick start\n",
    "-----------\n",
    "1. Activate your project environment (use the project's virtual environment).\n",
    "2. Install dependencies:\n",
    "\n",
    "```powershell\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "3. Run Phase 2 notebook interactively, or execute headless:\n",
    "\n",
    "```powershell\n",
    "python -m nbconvert --to notebook --execute \"Notebooks\\Phase2.ipynb\" --output \"Notebooks\\Phase2_executed.ipynb\"\n",
    "```\n",
    "\n",
    "What the notebook does\n",
    "----------------------\n",
    "- Loads `Data/heart.csv` and prints dataset summary and basic stats.\n",
    "- Runs data quality checks (missing values, duplicates, problematic zeros and negatives).\n",
    "- Produces descriptive statistics, distribution plots, and categorical summaries.\n",
    "- Generates visualizations and saves a textual data-exploration report to `reports/phase2_data_exploration_report.txt`.\n",
    "\n",
    "Where outputs are saved\n",
    "----------------------\n",
    "- Visualizations: saved as `01_target_distribution.png`, `02_numerical_distributions.png`, `03_categorical_distributions.png` in the notebook working directory (or `visualizations/` if present).\n",
    "- Reports: `reports/phase2_data_exploration_report.txt` and `reports/phase2_session_summary.txt`.\n",
    "\n",
    "Notes and troubleshooting\n",
    "-------------------------\n",
    "- The notebook includes safeguards to create `visualizations/` and `reports/` directories before saving files. If you run cells out of order or modified the notebook, create these directories manually:\n",
    "\n",
    "```powershell\n",
    "mkdir visualizations\n",
    "mkdir reports\n",
    "```\n",
    "\n",
    "- On Windows, file write encoding defaults can cause errors for special characters; notebooks explicitly write reports using UTF-8 to avoid this.\n",
    "\n",
    "Recommendations (next steps)\n",
    "---------------------------\n",
    "1. Address data-quality issues discovered in Phase 2:\n",
    "   - Impute or handle zeros in `RestingBP` and `Cholesterol` (treat as missing).\n",
    "   - Remove or flag duplicates if found.\n",
    "2. Prepare a preprocessing plan in Phase 3:\n",
    "   - Encode categorical features (`Sex`, `ChestPainType`, `RestingECG`, `ST_Slope`, `ExerciseAngina`).\n",
    "   - Scale/transform skewed numerical features (e.g., `Cholesterol`, `Oldpeak`).\n",
    "3. Split the data into train/validation/test with stratification on `HeartDisease` and a fixed random seed.\n",
    "4. Run baseline models to validate predictive signal.\n",
    "\n",
    "Files to inspect\n",
    "----------------\n",
    "- `Notebooks/Phase2.ipynb` — main data exploration notebook.\n",
    "- `reports/phase2_data_exploration_report.txt` — generated textual report.\n",
    "- `reports/phase2_session_summary.txt` — brief session summary.\n",
    "- `Docs/Phase2_README.md` — related Phase 3 docs (if you proceed to Phase 3 EDA).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
